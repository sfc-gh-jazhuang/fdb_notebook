{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "hhzrzwwdkd6mg5ednanv",
   "authorId": "501304564857",
   "authorName": "JAZHUANG",
   "authorEmail": "jay.zhuang@snowflake.com",
   "sessionId": "34db784d-b659-4a6a-b7ce-278c3bcb4f35",
   "lastEditTime": 1763160632192
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ec86d7d-ac05-4de1-9ac3-fcd84cc0704c",
   "metadata": {
    "name": "overview",
    "collapsed": false
   },
   "source": "# Unistore Latency Spikes Investigation"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "latency_spikes"
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n# Query data from the FDB server logs table\nquery = \"\"\"\nSELECT * FROM SNOWHOUSE_IMPORT.PROD1.FDB_SERVER_LOGS_OLTP_V LIMIT 100\n\"\"\"\ndf = session.sql(query).to_pandas()\n\n# Display basic info about the dataset\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"Columns: {list(df.columns)}\")\n\n# Show first few rows\nprint(\"\\nFirst 5 rows:\")\nprint(df.head())\n\n# Display the dataframe in Streamlit if you want to visualize it\nst.dataframe(df)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "sql_test"
   },
   "source": "-- Welcome to Snowflake Notebooks!\n-- Try out a SQL cell to generate some data.\nselect\n  time_slice(time, 300, 'second') as TIMEBUCKET,\n  machine,\n  sum(\n      iff(\n          Type = 'RedwoodMetrics',\n          v:OpGetRange::float,\n          null\n      )\n  ) as query_num,\n  max(\n      iff(\n          Type = 'NormalReadLatencyMetrics',\n          v:\"P99\"::float,\n          null\n      )\n  ) as latency_p99,\n  sum(iff(Type = 'StorageMetrics', split_part(v:FetchRangeReadBytes, ' ', 1)::float, null)) as fetch_bytes,\n  sum(iff(Type = 'StorageMetrics', split_part(v:FetchRangeReadCount, ' ', 1)::float, null)) as fetch_count,\n  sum(iff(Type = 'StorageMetrics', split_part(v:RowsQueried, ' ', 1)::float, null)) as rows_read,\n  iff(\n    sum(\n      iff(\n        Type = 'RedwoodMetrics',\n        v:OpGetRange::float,\n        null\n      )\n    ) = 0,\n    null,\n    sum(iff(Type = 'StorageMetrics', split_part(v:FetchRangeReadBytes, ' ', 1)::float, null)) /\n    sum(\n      iff(\n        Type = 'RedwoodMetrics',\n        v:OpGetRange::float,\n        null\n      )\n    )\n  ) as bytes_per_query,\n    iff(\n    sum(\n      iff(\n        Type = 'RedwoodMetrics',\n        v:OpGetRange::float,\n        null\n      )\n    ) = 0,\n    null,\n    sum(iff(Type = 'StorageMetrics', split_part(v:RowsQueried, ' ', 1)::float, null)) /\n    sum(\n      iff(\n        Type = 'RedwoodMetrics',\n        v:OpGetRange::float,\n        null\n      )\n    )\n  ) as rows_per_query\nfrom\n  SNOWHOUSE_IMPORT.PROD1.FDB_SERVER_LOGS_OLTP_V\nwhere\n  Type in ('RedwoodMetrics', 'NormalReadLatencyMetrics', 'StorageMetrics')\n  and log_group = 'prod1_autoprovision_88_100_fdbserver'\n  and TIMEBUCKET between '2025-11-01 00:00:00'::timestamp_ntz\n  and '2025-11-06 00:00:00'::timestamp_ntz\ngroup by\n  TIMEBUCKET, machine\nhaving\n  latency_p99 > 1\norder by latency_p99 desc;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ea2b86ac-1f00-4e92-9dda-71cf52b0042a",
   "metadata": {
    "language": "sql",
    "name": "sql_test2"
   },
   "outputs": [],
   "source": "WITH high_latency_events AS (\n    SELECT\n        TIME,\n        MACHINE,\n        v:\"P99\"::float as latency_p99\n    FROM\n        SNOWHOUSE_IMPORT.PROD1.FDB_SERVER_LOGS_OLTP_V\n    WHERE\n        Type = 'NormalReadLatencyMetrics'\n        AND v:\"P99\"::float > 0.5\n        AND log_group = 'prod1_autoprovision_88_100_fdbserver'\n        AND TIME BETWEEN '2025-10-31 00:00:00'::timestamp_ntz\n        AND '2025-11-06 00:00:00'::timestamp_ntz\n),\nredwood_metrics AS (\n    SELECT\n        TIME,\n        MACHINE,\n        v:OpGetRange::float as op_get_range,\n        COALESCE(v:OpTryNext::float, 0) + \n        COALESCE(v:OpNext::float, 0) + \n        COALESCE(v:OpNextBatch::float, 0) as op_nexts\n    FROM\n        SNOWHOUSE_IMPORT.PROD1.FDB_SERVER_LOGS_OLTP_V\n    WHERE\n        Type = 'RedwoodMetrics'\n        AND log_group = 'prod1_autoprovision_88_100_fdbserver'\n        AND TIME BETWEEN '2025-10-31 00:00:00'::timestamp_ntz\n        AND '2025-11-06 00:00:00'::timestamp_ntz\n),\nstorage_metrics AS (\n    SELECT\n        TIME,\n        MACHINE,\n        split_part(v:ClearRangeMutations, ' ', 1)::float as clear_range_mutations,\n        split_part(v:GetRangeQueries, ' ', 1)::float as ss_get_range\n    FROM\n        SNOWHOUSE_IMPORT.PROD1.FDB_SERVER_LOGS_OLTP_V\n    WHERE\n        Type = 'StorageMetrics'\n        AND log_group = 'prod1_autoprovision_88_100_fdbserver'\n        AND TIME BETWEEN '2025-10-31 00:00:00'::timestamp_ntz\n        AND '2025-11-06 00:00:00'::timestamp_ntz\n        AND v:ClearRangeMutations IS NOT NULL\n)\nSELECT\n    h.TIME as high_latency_time,\n    h.MACHINE,\n    h.latency_p99,\n    SUM(r.op_get_range) as total_op_get_range_1min_before,\n    SUM(r.op_nexts) as total_op_nexts_1min_before,\n    SUM(s.clear_range_mutations) as total_clear_range_mutations_1min_before,\n    SUM(s.ss_get_range) as total_ss_get_range_1min_before\nFROM\n    high_latency_events h\n    LEFT JOIN redwood_metrics r ON h.MACHINE = r.MACHINE\n        AND r.TIME BETWEEN DATEADD('minute', -1, h.TIME)\n        AND DATEADD('second', 5, h.TIME)\n    LEFT JOIN storage_metrics s ON h.MACHINE = s.MACHINE\n        AND s.TIME BETWEEN DATEADD('minute', -1, h.TIME)\n        AND DATEADD('second', 5, h.TIME)\nGROUP BY\n    h.TIME,\n    h.MACHINE,\n    h.latency_p99\nHAVING\n    SUM(r.op_get_range) < 10000\n    AND SUM(r.op_nexts) < 10000\n    AND SUM(s.ss_get_range) > 100\nORDER BY\n    h.TIME DESC;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "source": "# Then, we can use the python name to turn cell2 into a Pandas dataframe\nmy_df = cell2.to_pandas()\n\n# Chart the data\nst.subheader(\"Chance of SNOW ‚ùÑÔ∏è\")\nst.line_chart(my_df, x='SNOWDAY', y='CHANCE_OF_SNOW')\n\n# Give it a go!\nst.subheader(\"Try it out yourself and show off your skills ü•á\")",
   "execution_count": null,
   "outputs": []
  }
 ]
}